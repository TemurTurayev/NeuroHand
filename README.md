# ðŸ§  NeuroHand - EEG-Controlled Bionic Prosthetic Hand

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-In_Development-yellow.svg)

**An affordable, AI-powered brain-computer interface (BCI) prosthetic hand controlled by EEG signals.**

> *Developed by a 5th-year medical student at TashPMI with a focus on accessible biomedical engineering solutions.*

---

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Status](#project-status)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Technical Details](#technical-details)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)

---

## ðŸŽ¯ Overview

NeuroHand aims to create an **affordable EEG-controlled prosthetic hand** (target price: $1,500-2,000) compared to existing solutions ($40,000-100,000). The system uses:

- **Non-invasive EEG** (OpenBCI Cyton - 8 channels)
- **Deep Learning** (EEGNet architecture)
- **Servo-driven prosthetic** (tendon-based mechanism)
- **Adaptive learning** (online calibration)

### Key Differentiators

âœ… **Affordable**: ~$530 manufacturing cost at scale
âœ… **Non-invasive**: No surgery required
âœ… **Adaptive**: Learns from user over time
âœ… **Open-source**: Built on open hardware/software
âœ… **Real-time**: <500ms latency target

---

## âœ¨ Features

### Current (Pre-Hardware Phase)

- âœ… **Baseline EEGNet Model** trained on BCI Competition IV Dataset 2a
- âœ… **Preprocessing Pipeline** for 250Hz EEG signals
- âœ… **4-Class Motor Imagery** classification (L hand, R hand, feet, tongue)
- âœ… **Transfer Learning Ready** for OpenBCI data
- âœ… **Visualization Tools** for EEG signals and model performance

### Planned (Post-Hardware)

- ðŸ”„ **OpenBCI Integration** (arriving soon)
- ðŸ”„ **Real-time Prediction** pipeline
- ðŸ”„ **Prosthetic Control System** (Arduino + servos)
- ðŸ”„ **Online Learning** with Elastic Weight Consolidation (EWC)
- ðŸ”„ **Safety Mechanisms** (confidence thresholds, voting, watchdog)

---

## ðŸ“Š Project Status

**Phase**: Pre-Hardware Development (Training baseline model)

| Component | Status | Progress |
|-----------|--------|----------|
| Data Pipeline | âœ… Complete | 100% |
| EEGNet Model | âœ… Complete | 100% |
| Baseline Training | ðŸ”„ In Progress | 90% |
| OpenBCI Integration | â³ Waiting | 0% |
| Prosthetic Hardware | â³ Planned | 0% |
| Real-time System | â³ Planned | 0% |

**Waiting for**: OpenBCI Cyton v3 (shipping)

---

## ðŸš€ Installation

### Prerequisites

- **Python**: 3.9 or higher
- **OS**: macOS (M-series optimized), Linux, or Windows
- **RAM**: 8GB minimum, 16GB recommended
- **Storage**: ~2GB for datasets

### Step 1: Clone Repository

```bash
git clone https://github.com/TemurTurayev/NeuroHand.git
cd NeuroHand
```

### Step 2: Create Virtual Environment

```bash
# Create virtual environment
python -m venv venv

# Activate (macOS/Linux)
source venv/bin/activate

# Activate (Windows)
venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### Step 4: Verify Installation

```bash
python -c "import torch; import mne; print('âœ… Installation successful!')"
```

---

## ðŸŽ“ Quick Start

### Option A: Interactive Notebooks (Recommended for Beginners)

```bash
jupyter lab
```

Then open:
1. `notebooks/01_explore_data.ipynb` - Understand EEG data
2. `notebooks/02_preprocessing.ipynb` - Learn signal processing
3. `notebooks/03_model_training.ipynb` - Train and evaluate model

### Option B: Command Line Training

```bash
# Download BCI Competition IV-2a dataset
python src/data/download.py

# Preprocess data
python src/data/preprocessing.py

# Train model
python src/training/train.py --epochs 300 --batch_size 64

# Evaluate
python src/training/evaluate.py --checkpoint models/checkpoints/best_model.pth
```

### Option C: Quick Demo

```python
from src.models.eegnet import EEGNet
from src.data.dataset import BCIDataset
import torch

# Load pre-trained model
model = EEGNet(n_classes=4, n_channels=22, n_samples=1000)
model.load_state_dict(torch.load('models/checkpoints/best_model.pth'))

# Load test data
dataset = BCIDataset(data_path='data/processed/', split='test')
signal, label = dataset[0]

# Predict
with torch.no_grad():
    prediction = model(signal.unsqueeze(0))
    class_id = prediction.argmax(dim=1).item()

print(f"Predicted class: {['Left Hand', 'Right Hand', 'Feet', 'Tongue'][class_id]}")
```

---

## ðŸ“ Project Structure

```
NeuroHand/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # BCI Competition IV-2a (auto-downloaded)
â”‚   â””â”€â”€ processed/              # Preprocessed numpy arrays
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ download.py         # Dataset download script
â”‚   â”‚   â”œâ”€â”€ preprocessing.py    # Signal filtering & epoching
â”‚   â”‚   â””â”€â”€ dataset.py          # PyTorch Dataset class
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ eegnet.py           # EEGNet architecture
â”‚   â”‚   â””â”€â”€ utils.py            # Model utilities
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train.py            # Training loop
â”‚   â”‚   â”œâ”€â”€ evaluate.py         # Evaluation & metrics
â”‚   â”‚   â””â”€â”€ config.py           # Hyperparameters
â”‚   â””â”€â”€ visualization/
â”‚       â”œâ”€â”€ plot_signals.py     # EEG visualization
â”‚       â””â”€â”€ plot_results.py     # Training curves, confusion matrix
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_explore_data.ipynb   # Dataset exploration
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb  # Signal processing tutorial
â”‚   â””â”€â”€ 03_model_training.ipynb # Interactive training
â”œâ”€â”€ models/
â”‚   â””â”€â”€ checkpoints/            # Saved model weights
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ Claude.pdf              # Technical specifications (RU)
â”‚   â””â”€â”€ Claude1.pdf             # 12-week implementation plan (RU)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ CLAUDE.md                   # Developer configuration
â””â”€â”€ .gitignore
```

---

## ðŸ”¬ Technical Details

### EEG Signal Processing

- **Sampling Rate**: 250 Hz (matches OpenBCI)
- **Bandpass Filter**: 4-38 Hz (motor imagery relevant frequencies)
- **Epoch Length**: 4 seconds (1000 samples at 250Hz)
- **Channels**: 22 (BCI IV-2a) â†’ 8 (OpenBCI) via channel selection
- **Artifacts**: ICA-based removal (eye blinks, muscle activity)

### EEGNet Architecture

```
Input: [Batch, 1, Channels, Samples]
       [B, 1, 22, 1000]

Block 1: Temporal Convolution
â”œâ”€â”€ Conv2D(1â†’8, kernel=[1, 64])
â”œâ”€â”€ BatchNorm
â””â”€â”€ DepthwiseConv2D(8â†’16, kernel=[22, 1])
    â””â”€â”€ Captures spatial filters

Block 2: Separable Convolution
â”œâ”€â”€ DepthwiseConv2D(16â†’16, kernel=[1, 16])
â”œâ”€â”€ PointwiseConv2D(16â†’16)
â””â”€â”€ AveragePooling

Output: [Batch, n_classes]
```

**Parameters**: ~3,000 (extremely lightweight!)

### Training Details

- **Optimizer**: Adam (lr=0.001)
- **Loss**: CrossEntropyLoss
- **Batch Size**: 64
- **Epochs**: 300
- **Early Stopping**: Patience 50
- **Data Augmentation**: Time shifting, amplitude scaling
- **Regularization**: Dropout (0.5), L2 weight decay

### Expected Performance

| Metric | BCI IV-2a | Your OpenBCI (expected) |
|--------|-----------|-------------------------|
| **Accuracy** | 70-75% | 65-80% (after fine-tuning) |
| **Training Time** | ~30-60 min | ~5-10 min (transfer learning) |
| **Inference Time** | ~10ms | ~10-20ms (on RPi 5) |
| **Model Size** | ~50KB | Same |

---

## ðŸ—ºï¸ Roadmap

### âœ… Phase 1: Pre-Hardware (Current)

- [x] Project setup & documentation
- [x] BCI Competition IV-2a dataset integration
- [x] Preprocessing pipeline
- [x] EEGNet implementation
- [ ] Baseline model training (90% complete)
- [x] Jupyter notebooks for learning

### ðŸ”„ Phase 2: OpenBCI Integration (Next)

- [ ] OpenBCI Python integration
- [ ] Real-time signal streaming (LSL)
- [ ] Personal data collection protocol
- [ ] Transfer learning on personal data
- [ ] Online calibration system

### â³ Phase 3: Prosthetic Hardware (Month 2-3)

- [ ] 3D print Open Bionics Brunel Hand
- [ ] Arduino Mega servo control
- [ ] Serial communication protocol
- [ ] Safety mechanisms (watchdog, thresholds)
- [ ] Integrated testing

### â³ Phase 4: Optimization & Deployment (Month 3+)

- [ ] Raspberry Pi 5 deployment
- [ ] Online learning (EWC)
- [ ] Battery optimization (6-8 hour target)
- [ ] User testing & iteration
- [ ] Documentation & open-source release

---

## ðŸ¤ Contributing

This project is in **early development**. Contributions, suggestions, and collaborations are welcome!

### Ways to Contribute

- ðŸ› Report bugs or issues
- ðŸ’¡ Suggest features or improvements
- ðŸ“ Improve documentation
- ðŸ§ª Test on different hardware
- ðŸ¤ Collaborate on research

### Contact

- **GitHub**: [@TemurTurayev](https://github.com/TemurTurayev)
- **Email**: temurturayev7822@gmail.com
- **Telegram**: @Turayev_Temur
- **LinkedIn**: [Temur Turaev](https://linkedin.com/in/temur-turaev-389bab27b/)

---

## ðŸ“š Resources & References

### Scientific Papers

1. **EEGNet**: Lawhern et al. (2018) - "EEGNet: A Compact Convolutional Neural Network for EEG-based Brain-Computer Interfaces"
2. **BCI Competition IV**: Tangermann et al. (2012) - "Review of the BCI Competition IV"
3. **Motor Imagery**: Pfurtscheller & Neuper (2001) - "Motor imagery and direct brain-computer communication"

### Datasets

- [BCI Competition IV-2a](http://www.bbci.de/competition/iv/) - 9 subjects, 4-class MI
- [PhysioNet Motor Imagery](https://physionet.org/content/eegmmidb/) - 109 subjects, 2-class MI

### Communities

- [OpenBCI Community](https://openbci.com/community/)
- [NeuroTechX](https://neurotechx.com/)
- [BCI Society](https://bcisociety.org/)

---

## âš–ï¸ License

MIT License - See [LICENSE](LICENSE) file for details.

**Note**: This is a research/educational project. Not approved for medical use. Consult with healthcare professionals before any clinical application.

---

## ðŸ™ Acknowledgments

- **OpenBCI** - Open-source EEG hardware
- **Open Bionics** - Open-source prosthetic hand design
- **BCI Competition** - Public datasets
- **MNE-Python** - EEG processing tools
- **TashPMI** - Academic support

---

## ðŸ“Š Project Metrics

![GitHub Stars](https://img.shields.io/github/stars/TemurTurayev/NeuroHand?style=social)
![GitHub Forks](https://img.shields.io/github/forks/TemurTurayev/NeuroHand?style=social)

**Current Stats**:
- ðŸ§  Model Accuracy: Training in progress
- ðŸ“¦ Dataset: BCI Competition IV-2a (9 subjects, 288 trials each)
- ðŸ”¬ Code Status: 60% complete
- ðŸ“š Documentation: 80% complete

---

*Last updated: 2025-11-12*
*Developed with â¤ï¸ for accessible healthcare technology*

**ÐÐ˜ÐšÐžÐ“Ð”Ð ÐÐ• Ð¡Ð”ÐÐ’ÐÐ™Ð¡Ð¯!** ðŸ’ª
